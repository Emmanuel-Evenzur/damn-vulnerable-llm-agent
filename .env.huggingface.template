model="huggingface/meta-llama/Llama-3.1-8B-Instruct"
HF_TOKEN=<Huggingface token>

# To use a Hugging Face model, specify both the provider and model you want to use in the following format:
# huggingface/<provider>/<hf_org_or_user>/<hf_model>
# Where <hf_org_or_user>/<hf_model> is the Hugging Face model ID and <provider> is the inference provider.

#List of models 
# https://endpoints.huggingface.co/catalog?task=text-generation
